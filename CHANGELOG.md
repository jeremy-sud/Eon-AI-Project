# Changelog

Todos los cambios notables del Proyecto E√≥n.

## [1.5.0] - 2025-12-08

### Chat Conversacional Avanzado (NUEVO)

- **Predicci√≥n de Secuencias Num√©ricas**: Detecci√≥n autom√°tica de patrones (aritm√©tico, geom√©trico, Fibonacci, potencias, cuadr√°tico)
  - Ejemplo: "4, 8, 16, 32" ‚Üí "El siguiente valor es: **64**"
  - Soporte para m√∫ltiples valores: "siguientes 3 n√∫meros: 4, 8, 16, 32" ‚Üí "**64, 128, 256**"
  
- **Memoria Personal**: Almacena y recuerda hechos sobre el usuario
  - "Mi color favorito es ultramarino" ‚Üí "Guardar√© que color favorito: ultramarino üß†"
  - "¬øCu√°l es mi color favorito?" ‚Üí "Tu color favorito es ultramarino"
  
- **Base de Conocimiento T√©cnico**: Definiciones de conceptos clave
  - Entrop√≠a, ESN, Spirit Hash, Reservorio, Aprendizaje Hebbiano, Mackey-Glass, Cuantizaci√≥n
  
- **Consulta de Sensores**: Simulaci√≥n del sistema colectivo
  - "estado del SENSOR-3" ‚Üí Datos simulados (temperatura, humedad, bater√≠a, estado)
  - Manejo de reportes de falla con generaci√≥n de tickets
  
- **Afirmaciones Generales**: Confirmaci√≥n de hechos del mundo
  - "El cielo es azul" ‚Üí "Correcto. Mi base de conocimiento lo confirma ‚úì"
  
- **Autocompletado de Texto**: Completaci√≥n contextual de frases
  - "La velocidad del viento..." ‚Üí completaci√≥n relevante

### Mejoras en Detecci√≥n de Intenciones

- **20+ Categor√≠as de Intenci√≥n**: Expandido desde 17 categor√≠as
- **Detecci√≥n Autom√°tica de Secuencias**: 3+ n√∫meros separados por comas se detectan autom√°ticamente
- **Mejor Extracci√≥n de N√∫meros**: Ignora n√∫meros en texto contextual ("siguientes 3 n√∫meros")
- **Patrones de M√∫ltiples Valores**: Soporte para "siguientes N n√∫meros"

### Correcciones de Chat

- **Matem√°ticas Mejoradas**: "¬øCu√°nto es 34*5?" ‚Üí "El resultado es **170** üßÆ"
- **Historias Tem√°ticas**: "Cu√©ntame una historia de aventura" genera historias apropiadas
- **Recomendaciones Contextuales**: "¬øQu√© helado me recomiendas?" ‚Üí recomendaciones espec√≠ficas
- **Eliminaci√≥n de Falsos Positivos**: "cu√©ntame" ya no activa saludo
- **Orden de Patrones Optimizado**: Saludos al final para evitar conflictos

### Nuevos M√©todos Internos

- `_predict_sequence()`: Predicci√≥n de patrones num√©ricos con soporte multi-valor
- `_store_personal_fact()`: Almacenamiento de hechos personales
- `_recall_personal_fact()`: Recuperaci√≥n de memoria personal
- `_get_knowledge()`: Acceso a base de conocimiento t√©cnico
- `_query_sensor()`: Simulaci√≥n de consultas a sensores
- `_complete_text()`: Autocompletado contextual
- `_contains_sequence()`: Detecci√≥n autom√°tica de secuencias

## [1.4.0] - 2024-12-08

### Sistema de Aprendizaje Continuo (NUEVO)

- **OnlineLearner**: Actualizaci√≥n en tiempo real de W_out usando Recursive Ridge Regression
- **LongTermMemory**: Almacenamiento persistente de usuarios, hechos y estad√≠sticas
- **FeedbackSystem**: Mejora basada en retroalimentaci√≥n üëç/üëé de usuarios
- **ConsolidationEngine**: Optimizaci√≥n durante inactividad ("sue√±o"), refuerza patrones exitosos

### Mejoras en Generaci√≥n de Im√°genes

- **5 Estilos de Arte**: fractal, flow, particles, waves, neural
- **12 Paletas de Colores**: desde cosmic hasta fire
- **Semillas √önicas**: Cada imagen es genuinamente diferente basada en timestamp + hash

### Sistema de Chat Mejorado

- **17 Categor√≠as de Intenci√≥n**: identidad, saludo, imagen, c√≥digo, filosof√≠a, memoria, etc.
- **Detecci√≥n Mejorada**: Sin falsos positivos en nombres propios
- **Respuestas Contextuales**: Mayor coherencia que TinyLMv2 para este caso de uso

### Nuevos Endpoints API

- `POST /api/feedback` - Enviar feedback üëç/üëé sobre respuestas
- `GET /api/learning-stats` - Estad√≠sticas de aprendizaje
- `GET|DELETE /api/memory` - Gesti√≥n de memoria a largo plazo
- `POST /api/consolidate` - Forzar consolidaci√≥n manual

### Panel de Aprendizaje (Frontend)

- Visualizaci√≥n de eventos de aprendizaje
- Lista de usuarios conocidos
- Lista de hechos aprendidos
- Estad√≠sticas de feedback
- Botones de consolidaci√≥n y limpieza de memoria
- Botones üëç/üëé en cada mensaje de IA

### Persistencia

- `long_term_memory.json` - Usuarios, hechos, stats de aprendizaje
- `feedback.json` - Historial de valoraciones por patr√≥n

### Benchmark Integral v2.0

- Nuevo archivo `benchmark_full.py` en ra√≠z
- 8 m√≥dulos de prueba (ESN, cuantizaci√≥n, plasticidad, TinyLM, aprendizaje, memoria, im√°genes, sistema)
- Modos `--quick` y `--export`
- Resultados verificados: 8-bit retiene 99.6% precisi√≥n

## [1.3.0] - 2024-12-08

### Sistema de Memoria y Estad√≠sticas

- **Historial Persistente**: Conversaciones guardadas en `chat_history.json`
- **Estad√≠sticas de Uso**: Tracking de mensajes, im√°genes, archivos procesados
- **Aprendizaje desde Archivos**: Soporte para .txt, .md, .py, .js, .json, .csv
- **Configuraci√≥n de Personalidad**: Estilos (formal, casual, creative, precise, balanced)

### Nuevos Endpoints API

- `GET /api/stats` - Estad√≠sticas de uso completas
- `GET|DELETE /api/history` - Gesti√≥n del historial de chat
- `GET|POST /api/personality` - Configuraci√≥n de personalidad
- `POST /api/learn-text` - Aprender de texto nuevo
- `POST /api/upload` - Subir archivos para aprendizaje

### Mejoras de Frontend

- Panel de Estad√≠sticas de Uso (mensajes, im√°genes, archivos, uptime)
- Panel de Personalidad (selector de estilo y verbosidad)
- Bot√≥n "Limpiar Historial"
- Subida de archivos funcional con aprendizaje real
- Actualizaci√≥n autom√°tica de estad√≠sticas cada 30s

### Correcciones

- Mejorada integraci√≥n frontend-backend
- Persistencia de estad√≠sticas entre sesiones

## [1.2.0] - 2024-12-08

### Integraci√≥n TinyLMv2 en Chat

- **Modelo de Lenguaje**: TinyLMv2 integrado para respuestas generativas
- **Entrenamiento Autom√°tico**: Se entrena al iniciar con textos filos√≥ficos
- **Respuestas H√≠bridas**: Intenciones conocidas usan respuestas predefinidas, mensajes gen√©ricos usan el LM
- **Nuevo Endpoint**: `/api/lm-status` para ver estado del modelo de lenguaje
- **Configuraci√≥n Din√°mica**: La temperatura y max_tokens afectan la generaci√≥n

### Estad√≠sticas del Modelo

- 256 neuronas en el reservorio
- 102 palabras en vocabulario
- 99.9% accuracy en entrenamiento
- Embeddings de 32 dimensiones

## [1.1.0] - 2024-12-08

### Interfaz Web Principal (web/)

- **Servidor Flask**: API REST completa en `web/server.py`
- **Chat Conversacional**: Sistema de respuestas basado en detecci√≥n de intenciones
- **Generaci√≥n de Arte Neuronal**: Endpoint `/api/generate-image` usando ESN
- **Configuraci√≥n de IA**: Par√°metros t√≠picos (temperatura, top-p, max_tokens, etc.)
- **Estado del Sistema**: Endpoint `/api/status` con informaci√≥n del Momento Cero
- **Interfaz Moderna**: Chat, Dream (visualizaci√≥n), Estado & Config

### Correcciones

- Corregido `DATA_DIR` no definido en server.py
- Eliminado endpoint `/api/birth` (reemplazado por `/api/genesis` solo lectura)
- E√≥n siempre existe desde el Momento Cero (inmutable)
- Botones de imagen y subir archivo ahora funcionales

### Limpieza de C√≥digo

- Eliminado `phase3-integration/demos/aeon.js` (duplicado)
- Eliminado directorio `venv` duplicado (se conserva `.venv`)
- Actualizada referencia en `phase3-integration/demos/index.html`

## [1.0.0] - 2024-12-08

### Fase 1: Fundamentos

- Echo State Network en Python con NumPy
- Cuantizaci√≥n 8-bit, 4-bit, 1-bit
- Plasticidad Hebbiana, STDP, Anti-Hebbiana
- M√≥dulo Genesis (Momento Cero)

### Fase 2: N√∫cleo C

- **Benchmarks de Energ√≠a**: E√≥n (0.0045 ŒºJ) vs TinyML (0.0015 ŒºJ) en Cortex-M4.
- **Documentaci√≥n Completa**: Arquitectura, benchmarks, y gu√≠as de uso actualizadas.

### Fase 2: N√∫cleo C

- libAeon: 1.3KB de memoria
- Aritm√©tica de punto fijo Q8.8
- Entrenamiento Gauss-Jordan
- Persistencia binaria

### Fase 3: Integraci√≥n Web

- aeon.js: N√∫cleo JavaScript puro
- Demo interactivo en navegador
- Visualizaci√≥n en tiempo real

### Fase 4: Hardware

- Librer√≠a Arduino (Aeon.h)
- Extensi√≥n ESP32 con WiFi
- Ejemplos de predicci√≥n

### Fase 9: Empaquetado

- **Empaquetado**: NPM, PyPI, Arduino Library.

### Fase 10: Generaci√≥n de Paper Acad√©mico

- **Generaci√≥n de Paper Acad√©mico**: (LaTeX) para arXiv.

### Fase 5: Aplicaciones IoT

- Predictor de temperatura
- Detector de anomal√≠as
- Dashboard (pendiente)

### Fase 6: Mente Colectiva

- **Intercambio 1-Bit**: Protocolo MQTT ultraligero para ESP32 (`phase6-collective/src`).
- Compresi√≥n 17x (Float32 -> 1-Bit) para transmisi√≥n de pesos.
- AeonNode: Nodo individual
- CollectiveMind: Coordinador
- Sincronizaci√≥n de pesos W_out

### Fase 7: TinyLM

- v1: Tokenizaci√≥n por caracteres
- v2: Tokenizaci√≥n por palabras (99.9% accuracy)
- **Trie Dictionary**: Vocabulario comprimido basado en LCRS arrays (`phase7-language/src/trie_vocab.py`).
- Servidor web Flask

### Fase 8: Paper Acad√©mico

- Template LaTeX completo
- Comparativas formales
- Listo para arXiv

---

(c) 2024 Sistemas Ursol - Jeremy Arias Solano
