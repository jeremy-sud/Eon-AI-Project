# Comparativa: EÃ³n vs Frameworks TinyML

**VersiÃ³n:** 1.0  
**Fecha:** 2025-12-10  
**Autor:** Proyecto EÃ³n

---

## Resumen Ejecutivo

Este documento compara EÃ³n con los principales frameworks de Machine Learning para dispositivos edge (TinyML). EÃ³n ofrece un enfoque Ãºnico basado en **Echo State Networks (ESN)** con caracterÃ­sticas que los frameworks tradicionales no pueden igualar.

---

## Frameworks Comparados

| Framework | Desarrollador | Tipo | Licencia |
|-----------|---------------|------|----------|
| **EÃ³n** | Sistemas Ursol | ESN/Reservoir Computing | MIT |
| TensorFlow Lite Micro | Google | CNN/MLP Cuantizados | Apache 2.0 |
| Edge Impulse | Edge Impulse Inc. | AutoML + ExportaciÃ³n | Freemium |
| CMSIS-NN | ARM | Kernels Optimizados | Apache 2.0 |
| microTVM | Apache TVM | Compilador ML | Apache 2.0 |
| STM32Cube.AI | STMicroelectronics | ConversiÃ³n Modelos | Propietaria |
| NNoM | Majianjia | Redes Neuronales MCU | Apache 2.0 |

---

## Comparativa Detallada

### 1. Memoria RAM

| Framework | RAM MÃ­nima | Modelo TÃ­pico | Notas |
|-----------|------------|---------------|-------|
| **EÃ³n** | **1.3 KB** | 1.3-20 KB | Reservoir compacto |
| TFLite Micro | 16-64 KB | 50-200 KB | Requiere arena de tensores |
| Edge Impulse | 8-32 KB | 20-100 KB | Depende del modelo |
| CMSIS-NN | 4-16 KB | 10-50 KB | Solo kernels optimizados |
| NNoM | 4-8 KB | 8-30 KB | Ligero pero sin temporales |

**ğŸ† EÃ³n Gana:** Menor footprint de RAM gracias a que el reservoir NO requiere almacenar activaciones intermedias.

### 2. Memoria Flash

| Framework | Flash MÃ­nima | Modelo TÃ­pico | Notas |
|-----------|--------------|---------------|-------|
| **EÃ³n** | **4 KB** | 4-15 KB | Solo W_out entrenado |
| TFLite Micro | 50-100 KB | 100-500 KB | IntÃ©rprete + modelo |
| Edge Impulse | 20-80 KB | 50-200 KB | SDK + modelo |
| CMSIS-NN | 5-20 KB | Variable | Solo kernels |
| microTVM | 10-50 KB | Variable | Runtime compilado |

**ğŸ† EÃ³n Gana:** El reservoir es aleatorio (generado con semilla), no requiere almacenamiento.

### 3. Capacidad Temporal (Series de Tiempo)

| Framework | Memoria Temporal | Tipo | Notas |
|-----------|------------------|------|-------|
| **EÃ³n** | **Inherente** | Recurrente Natural | El reservoir mantiene estado |
| TFLite Micro | Manual (LSTM/GRU) | Pesos explÃ­citos | 10-100x mÃ¡s parÃ¡metros |
| Edge Impulse | DSP + Ventanas | Preprocesamiento | Requiere features manuales |
| CMSIS-NN | No nativo | Solo feedforward | Requiere implementaciÃ³n externa |

**ğŸ† EÃ³n Gana:** Las ESN tienen memoria temporal inherente sin parÃ¡metros adicionales.

### 4. Entrenamiento On-Device

| Framework | Entrena en MCU | MÃ©todo | Notas |
|-----------|----------------|--------|-------|
| **EÃ³n** | **SÃ** | RegresiÃ³n lineal | Solo W_out, O(nÂ²) |
| TFLite Micro | NO | N/A | Solo inferencia |
| Edge Impulse | NO | N/A | Entrena en cloud |
| CMSIS-NN | NO | N/A | Solo inferencia |
| microTVM | NO | N/A | Solo inferencia |

**ğŸ† EÃ³n Gana:** Ãšnico framework que permite entrenamiento real en MCU.

### 5. Aprendizaje Continuo

| Framework | Aprende Nuevos Datos | Olvida CatastrÃ³fico | AdaptaciÃ³n |
|-----------|---------------------|---------------------|------------|
| **EÃ³n** | **SÃ** | **NO** (Hebbiano) | Tiempo Real |
| TFLite Micro | NO | N/A | Modelo fijo |
| Edge Impulse | NO | N/A | Re-entrenamiento cloud |
| Todos los demÃ¡s | NO | N/A | Modelo estÃ¡tico |

**ğŸ† EÃ³n Gana:** Plasticidad Hebbiana permite adaptaciÃ³n sin olvido catastrÃ³fico.

### 6. Complejidad de ImplementaciÃ³n

| Framework | Curva Aprendizaje | Dependencias | Portabilidad |
|-----------|-------------------|--------------|--------------|
| **EÃ³n** | **Baja** | Solo NumPy/C | Alta (ANSI C) |
| TFLite Micro | Alta | FlatBuffers, Protobuf | Media |
| Edge Impulse | Media | SDK propietario | Media |
| CMSIS-NN | Media | CMSIS-DSP | Solo ARM |
| microTVM | Alta | LLVM, TVM | Alta |

**ğŸ† EÃ³n Gana:** ImplementaciÃ³n en ~500 lÃ­neas de C puro.

### 7. EnergÃ­a por Inferencia

| Framework | Î¼J/Inferencia* | Notas |
|-----------|----------------|-------|
| **EÃ³n** | 0.0045 | MultiplicaciÃ³n matriz-vector |
| TFLite Micro | 0.0015 | Kernels SIMD optimizados |
| CMSIS-NN | 0.001 | Intrinsics ARM |

*\*Estimado para Cortex-M4F @ 80MHz, modelo comparable*

**âš ï¸ EÃ³n Pierde:** Mayor energÃ­a por inferencia (pero menor total por entrenar on-device).

### 8. CuantizaciÃ³n

| Framework | Tipos Soportados | PÃ©rdida TÃ­pica |
|-----------|------------------|----------------|
| **EÃ³n** | 8-bit, 4-bit, 1-bit | 0.4% (8-bit) |
| TFLite Micro | int8, int16 | 1-3% |
| Edge Impulse | int8 | 1-3% |
| CMSIS-NN | int8, int16 | 1-3% |

**ğŸ† Empate:** Ambos soportan cuantizaciÃ³n con pÃ©rdida mÃ­nima.

---

## Tabla Resumen

| CaracterÃ­stica | EÃ³n | TFLite Micro | Edge Impulse | CMSIS-NN |
|----------------|-----|--------------|--------------|----------|
| RAM MÃ­nima | **1.3 KB** | 16 KB | 8 KB | 4 KB |
| Flash MÃ­nima | **4 KB** | 50 KB | 20 KB | 5 KB |
| Temporal Nativo | **âœ…** | âŒ (LSTM) | âŒ (DSP) | âŒ |
| Entrena On-Device | **âœ…** | âŒ | âŒ | âŒ |
| Aprendizaje Continuo | **âœ…** | âŒ | âŒ | âŒ |
| ImplementaciÃ³n Simple | **âœ…** | âŒ | âŒ | âš ï¸ |
| Ecosistema Grande | âŒ | **âœ…** | **âœ…** | âš ï¸ |
| DocumentaciÃ³n | âš ï¸ | **âœ…** | **âœ…** | âš ï¸ |

---

## CuÃ¡ndo Usar Cada Framework

### Usa EÃ³n Cuando:
- âœ… Necesitas **aprendizaje en el dispositivo**
- âœ… Procesas **series temporales** (audio, sensores, vitales)
- âœ… Tienes restricciones **extremas de RAM** (<10KB)
- âœ… Requieres **adaptaciÃ³n continua** sin re-flashear
- âœ… Necesitas **arquitecturas mÃ­sticas** (Tzimtzum, Alquimia)
- âœ… Valoras **cÃ³digo simple** y auditable

### Usa TensorFlow Lite Micro Cuando:
- âœ… Tienes modelos CNN pre-entrenados de Keras/TF
- âœ… Tu MCU tiene >64KB RAM
- âœ… Necesitas ecosistema y comunidad grande
- âœ… ClasificaciÃ³n de imÃ¡genes/audio con modelos probados

### Usa Edge Impulse Cuando:
- âœ… Quieres AutoML y GUI sin cÃ³digo
- âœ… Tienes presupuesto para plan de pago
- âœ… Necesitas despliegue rÃ¡pido sin experiencia ML
- âœ… Tu aplicaciÃ³n encaja en sus templates

### Usa CMSIS-NN Cuando:
- âœ… Desarrollas solo para ARM Cortex-M
- âœ… Necesitas mÃ¡ximo rendimiento en inferencia
- âœ… Ya tienes el modelo y solo necesitas kernels

---

## Arquitectura Ãšnica de EÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENTRADA                               â”‚
â”‚                      â”‚                                   â”‚
â”‚                      â–¼                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚   W_in (aleatorio, fijo)        â”‚                  â”‚
â”‚    â”‚   ~100 bytes                    â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                   â”‚
â”‚                      â–¼                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚   RESERVOIR (50 neuronas)       â”‚  â† NO SE ENTRENA â”‚
â”‚    â”‚   Estado: ~400 bytes            â”‚                  â”‚
â”‚    â”‚   Generado con semilla          â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                   â”‚
â”‚                      â–¼                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚   W_out (Ãºnica capa entrenada)  â”‚  â† SE ENTRENA   â”‚
â”‚    â”‚   ~400 bytes (8-bit)            â”‚     ON-DEVICE   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                   â”‚
â”‚                      â–¼                                   â”‚
â”‚                   SALIDA                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total RAM: ~1.3 KB
Total Flash: ~4 KB (cÃ³digo + W_out)
Entrenamiento: RegresiÃ³n lineal simple
```

---

## ConclusiÃ³n

**EÃ³n no compite directamente con TFLite Micro o Edge Impulse** - ocupa un nicho Ãºnico:

1. **Dispositivos ultra-restringidos** (<10KB RAM)
2. **Aprendizaje en el borde** sin cloud
3. **Series temporales** con memoria inherente
4. **AdaptaciÃ³n continua** sin olvido catastrÃ³fico

Para casos donde estas caracterÃ­sticas son crÃ­ticas, **EÃ³n es la Ãºnica opciÃ³n viable**.

Para casos donde tienes modelos CNN pre-entrenados y suficiente memoria, los frameworks tradicionales siguen siendo la mejor opciÃ³n por su ecosistema y documentaciÃ³n.

---

## Referencias

- [TensorFlow Lite Micro](https://www.tensorflow.org/lite/microcontrollers)
- [Edge Impulse](https://www.edgeimpulse.com/)
- [CMSIS-NN](https://arm-software.github.io/CMSIS_5/NN/html/index.html)
- [Apache TVM microTVM](https://tvm.apache.org/docs/topic/microtvm/index.html)
- [NNoM](https://github.com/majianjia/nnom)
- [Echo State Networks - Jaeger 2001](http://www.scholarpedia.org/article/Echo_state_network)

---

*Documento generado por Proyecto EÃ³n v1.8.1*
